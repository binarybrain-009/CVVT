{"cells":[{"cell_type":"markdown","metadata":{"id":"Uv_AZs3o90Oo"},"source":["#**ECE 4554 / ECE 5554 / Computer Vision**\n","This file contains the coding problems for Homework 3. Please implement/modify the sections within this notebook that are marked \"TO DO\".\n","\n","**Problems 4 and 5 are required for all students.\n","Problem 6 is required for 5554 students, but is optional for 4554 students**\n","\n","##**TO DO**: Enter your Virginia Tech Username (PID) here: ____________________\n","(Your Username is usually part of your email address, as in Username@vt.edu.)\n","\n","##**Honor Code reminder**\n","\n","Please review the Honor Code statement in the syllabus.  This is not a \"team project\". If you obtained code or were inspired by code from any source except the instructor, you must cite those sources using comment lines in your solution.  \n","\n","##**Code libraries**\n","You are allowed to use NumPy and Matplotlib functions to perform matrix operations and graphics/plotting operations. You are  allowed to use OpenCV functions for graphics/plotting, such as `cv2.circle` and `cv2.line`. You are also allowed to use any OpenCV functions that are provided in this start-up notebook, but do not use any other OpenCV functions without permission from the instructor.\n","\n","##**Submission guidelines** for the coding problems (Google Colab)\n","\n","1. Please verify that you have entered your Virginia Tech Username in all of the appropriate places.\n","2. After clicking Runtime->Run all, verify that all of your solutions are visible in this notebook.\n","3. Click File->Save near the top of the page to save the latest version of your notebook at Google Drive.\n","4. Verify that the last 2 cells have executed, creating a PDF version of this notebook at Google Drive. (Note: if you face difficulty with this step, please refer to https://pypi.org/project/notebook-as-pdf/)\n","5. Look at the PDF file and check that all of your solutions are displayed correctly there.\n","6. Download your notebook file and the PDF version to your laptop.\n","7. On your laptop, create a ZIP version of this notebook file. (Please don't include the separate data files.) Use file name Homework3_Code_USERNAME.zip, with your own Username.\n","6. For your PDF version, use file name Homework3_Notebook_USERNAME.pdf, with your own Username.\n","7. **Submit these 2 files and your PDF file for Problems 1-3 SEPARATELY to Canvas.** Do not zip them all together.\n","\n","##**Overview**\n","\n","For Problem 4,\n","you must write code that can solve for a *2D homography* using 2D point correspondences. You must also write code to perform image warping using your 2D homography solution.\n","\n","For problem 5,\n","you must write code to find the *fundamental matrix* for a stereo image pair. You  also need to write code to display keypoints and epipolar lines in the two images. For this problem, you may assume that no outliers are present in your set of corresponding image points.\n","\n","For Problem 6,\n","you will extend the previous problem by using RANSAC to address the problem of outliers.\n"]},{"cell_type":"markdown","metadata":{"id":"6JAJCmmPnS0O"},"source":["# **Environment setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UZyFSREnaux"},"outputs":[],"source":["# Mount your Google Drive to this notebook\n","# The purpose is to allow your code to access to your files\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LktsMf-_nX24"},"outputs":[],"source":["# Change the directory to your own working directory\n","# Any files under your working directory are available to your code\n","# TO DO: enter the name of your directory\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/HW3')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pUZSvqWnpEd"},"outputs":[],"source":["# Import library modules\n","import sys\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy\n","from scipy import optimize\n","from PIL import Image  # Python Imaging Library\n","# The following is a substitute for cv2.imshow,\n","#  which you would use on your local machine but Colab does not support it\n","from google.colab.patches import cv2_imshow\n","\n","print('Python version:', sys.version)\n","print('OpenCV version:', cv2.__version__)\n","print('NumPy version: ', np.__version__)\n"]},{"cell_type":"markdown","metadata":{"id":"tZVby_XkJ_Sq"},"source":["#**Getting started**\n","\n","Several image files were provided to you (including `mandrill.tif`, etc.). Upload all of those image files to your working directory.\n","\n","The following functions are helpful for loading images into floating-point format, and for displaying images that are in that format.  Let's use those functions to display an example image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_EnspGEEKsVf"},"outputs":[],"source":["def load_image(filename):\n","  img = np.asarray(Image.open(filename))\n","  img = img.astype(\"float32\")/255.0\n","  return img\n","\n","def show_image(img):\n","  fig = plt.figure()\n","  fig.set_size_inches(10, 8) # You can adjust the size of the displayed figure\n","  plt.imshow(img)\n","\n","mandrill_img = load_image(\"mandrill.tif\")\n","show_image(mandrill_img)\n"]},{"cell_type":"markdown","metadata":{"id":"Awo9Llpxi4No"},"source":["#**Problem 4: Image warping**\n","\n","**Part (a):  2D homography**\n","\n","Implement the 2 functions that are shown in the next code block. (OpenCV has a findHomography() function and other related functions, but for this assignment you must write your own versions.)\n","\n","1.   **compute_homography(src, dst)** receives two matrices, each of size Nx2. Each matrix contains N two-dimensional points. For each value of i, src[i] and dst[i] are corresponding points from two different images. The function should return the homography matrix H of size 3x3 that maps every point from the source (src) to the destination (dst).   *Guidance*: You may assume that N is at least 4. You can set up the problem in a matrix-based, least-squares format. (A somewhat similar problem is in the lecture slides on page 16 of packet 15.) Helpful functions are `np.linalg.eig()` and `np.linalg.eigh()` for computing eigenvalues and eigenvectors. The latter function will prevent warnings due to small imaginary values if you are working with matrices that are real and symmetric.\n","2.   **apply_homography(src, H)** receives points in matrix src (an Nx2 matrix), and a homography transformation H (a 3x3 matrix). This function should use the homography matrix to transform each point in src to a new destination point. Store the resulting points in matrix dst, which is the same size as src. The function should return dst. *Guidance*: Remember to use homogeneous coordinates when implementing this transformation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Shmty4g_jDN6"},"outputs":[],"source":["def compute_homography(src, dst):\n","  '''Computes the homography from src to dst.\n","   Input:\n","    src: source points, shape (N, 2), where N >= 4\n","    dst: destination points, shape (N, 2)\n","   Output:\n","    H: homography from source points to destination points, shape (3, 3)\n","\n","   TO DO: Implement the compute_homography function\n","  '''\n","  # The following line is temporary. Replace it with your code.\n","  H = np.identity(3)\n","\n","\n","  return H\n","\n","\n","def apply_homography(src, H):\n","  '''Applies a homography H to the source points.\n","   Input:\n","      src: source points, shape (N, 2)\n","      H: homography from source points to destination points, shape (3, 3)\n","   Output:\n","     dst: destination points, shape (N, 2)\n","\n","   TO DO: Implement the apply_homography function\n","  '''\n","  # The following line is temporary. Replace it with your code.\n","  dst = np.zeros([4, 2])\n","\n","\n","  return dst\n"]},{"cell_type":"markdown","metadata":{"id":"q5WBw3uYjRPH"},"source":["Use the following code block to test your homography code. Some example corresponding points are provided to you in src_pts and dst_pts. If your implementation is correct, it should map the points given in test_pts to locations that are close to the points given in match_pts_correct. If you have correctly implemented compute_homography() and apply_homography(), then the printed difference values should be close to 0. (A small difference, such as 0.001, should be acceptable.)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kg-jhh_DjTUx"},"outputs":[],"source":["# Do not modify this code block. If you would like to edit this code\n","#  for debugging purposes, copy it into a separate code block and edit that copy.\n","def test_homography():\n","  src_pts = np.matrix('0, 0; 1, 0; 1, 1; 0, 1')\n","  dst_pts = np.matrix('5, 4; 7, 4; 7, 5; 6, 6')\n","  H = compute_homography(src_pts, dst_pts)\n","  test_pts = np.matrix('0,  0; 1, 0; 1, 1; 0, 1')\n","  match_pts = apply_homography(test_pts, H)\n","  match_pts_correct = np.matrix('5, 4; 7, 4; 7, 5; 6, 6')\n","  print('Your 1st solution differs from our solution by: %f'\n","    % np.square(match_pts - match_pts_correct).sum())\n","\n","  src_pts = np.matrix('0, 0; 1, 0; 1, 1; 0, 1; 2, 3')\n","  dst_pts = np.matrix('5, 4; 7, 4; 7, 5; 6, 6; 7.25, 5.5')\n","  H = compute_homography(src_pts, dst_pts)\n","  test_pts = np.matrix('0,  0; 1, 0; 1, 1; 0, 1')\n","  match_pts = apply_homography(test_pts, H)\n","  match_pts_correct = np.matrix('5, 4; 7, 4; 7, 5; 6, 6')\n","  print('Your 2nd solution differs from our solution by: %f'\n","    % np.square(match_pts - match_pts_correct).sum())\n","\n","  src_pts = np.matrix('347, 313; 502, 341; 386, 571; 621, 508')\n","  dst_pts = np.matrix('274, 286; 436, 305; 305, 527; 615, 506')\n","  H = compute_homography(src_pts, dst_pts)\n","  test_pts = np.matrix('259, 505; 350, 371; 400, 675; 636, 104')\n","  match_pts = apply_homography(test_pts, H)\n","  match_pts_correct = np.matrix('195.13761083, 448.12645033;'\n","    '275.27269386, 336.54819916;'\n","    '317.37663747, 636.78403426;'\n","    '618.50438823, 28.78963905')\n","  print('Your 3rd solution differs from our solution by: %f'\n","    % np.square(match_pts - match_pts_correct).sum())\n","\n","test_homography()\n"]},{"cell_type":"markdown","metadata":{"id":"hqGfPlkmjbkh"},"source":["**Part (b):  Image warping using a 2D homography**\n","\n","Implement the following function so that it performs image warping from a source image (`src_img`) to a newly created destination image (`dst_img`). Do not use any additional OpenCV functions. The homography H that is provided indicates a desired mapping from `src_img` to `dst_img`.\n","\n","*Guidance:*  To prevent gaps in your output image, it is suggested that your implementation should iterate over all pixels in `dst_img`. In that case, your code should use the *inverse* of H to find values in `src_img` as it iterates over `dst_img`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxOySCKwjctu"},"outputs":[],"source":["def warp_img(src_img, H, dst_img_size):\n","  '''Warping of a source image using a homography.\n","   Input:\n","      src_img: source image with shape (m, n, 3)\n","      H: homography, with shape (3, 3), from source image to destination image\n","      dst_img_size: height and width of destination image; shape (2,)\n","   Output:\n","      dst_img: destination image; height and width specified by dst_img_size parameter\n","\n","   TO DO: Implement the warp_img function.\n","  '''\n","\n","  # The following line is temporary. Replace it with your code.\n","  dst_img = np.zeros([dst_img_size[0], dst_img_size[1], 3])\n","\n","\n","\n","\n","  return dst_img\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lc3kb72-miNZ"},"source":["The following will test your image_warp function by performing a 2D rotation. You do not need to change any code in the following block. If your code is correct, the output here should show a mandrill image that has been rotated by 10 degrees counterclockwise about the upper-left corner.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X95PWlWemjtD"},"outputs":[],"source":["# Do not modify this code block. If you would like to edit this code\n","#  for debugging purposes, copy it into a separate code block and edit that copy.\n","def test_rotation():\n","  src_img = load_image('mandrill.tif')\n","  canvas_img = np.zeros([src_img.shape[0], src_img.shape[1], 3])\n","\n","  theta = 10  # counterclockwise rotation angle in degrees\n","  H = [[np.cos(theta * np.pi/180), -np.sin(theta * np.pi/180), 0.0],\n","       [np.sin(theta * np.pi/180), np.cos(theta * np.pi/180), 0.0],\n","       [0.0, 0.0, 1.0]]\n","\n","  dst_img = warp_img(src_img, H, [canvas_img.shape[0], canvas_img.shape[1]])\n","  show_image(dst_img)\n","\n","test_rotation()\n"]},{"cell_type":"markdown","metadata":{"id":"aRZ_IHoTjhZL"},"source":["The following will test your image_warp function with a more general homography. You do not need to modify these functions. If your code is correct, the output here should show a  mandrill image that has been warped to overlay the blue side of a Rubik's cube.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EzizhiRjlaT"},"outputs":[],"source":["# Do not modify this code block. If you would like to edit this code\n","#  for debugging purposes, copy it into a separate code block and edit that copy.\n","def binary_mask(img):\n","  '''Create a binary mask of the image content.\n","   Input:\n","    img: source image, shape (m, n, 3)\n","   Output:\n","    mask: image of shape (m, n) and type 'int'. For pixel [i, j] of mask,\n","      if pixel [i, j] in img is nonzero in any channel, assign 1 to mask[i, j].\n","      Else, assign 0 to mask[i, j].\n","  '''\n","  mask = (img[:, :, 0] > 0) | (img[:, :, 1] > 0) | (img[:, :, 2] > 0)\n","  mask = mask.astype(\"int\")\n","  return mask\n","\n","def test_warp():\n","  src_img = load_image('mandrill.tif')\n","  canvas_img = load_image('Rubiks_cube.jpg')\n","\n","  # The following are corners of the mandrill image in (ROW, COLUMN) order\n","  src_pts = np.matrix('0, 0; 511, 0; 511, 511; 0, 511')\n","  # The following are corners of the blue face of the Rubik's cube\n","  canvas_pts = np.matrix('238, 218; 560, 225; 463, 490; 178, 530')\n","\n","  # The following was used during debugging\n","  # The center of the circle is specified using (COLUMN, ROW) coordinates\n","  # cv2.circle(canvas_img, (218, 238), 4, (255, 0, 0), thickness=10)\n","\n","  H = compute_homography(src_pts, canvas_pts)\n","  dst_img = warp_img(src_img, H, [canvas_img.shape[0], canvas_img.shape[1]])\n","  dst_mask = 1 - binary_mask(dst_img)\n","  dst_mask = np.stack((dst_mask,) * 3, -1)\n","  out_img = np.multiply(canvas_img, dst_mask) + dst_img\n","\n","  dsize = (600, 600) # width and height of canvas_im\n","  src_smaller = cv2.resize(src_img, dsize, interpolation=cv2.INTER_AREA)\n","\n","  warped_img = np.concatenate((src_smaller, canvas_img, out_img), axis=1)\n","  show_image(np.clip(warped_img, 0, 1))\n","\n","test_warp()\n"]},{"cell_type":"markdown","metadata":{"id":"DijeEI7j21Fk"},"source":["Next, you must demonstrate your image warping code by mapping a desert image onto a billboard. You have been given two images, `billboard.png` and `desert.png`.  In the code block below, write code that places an appropriately reshaped (warped) version of `desert.png` into the white billboard region within  `billboard.png`. Your solution must utilize your functions `compute_homography()` and `apply_homography()`, and must display the billboard image before and after it is modified.\n","\n","*Guidance*: Your code does not need to locate the billboard automatically. It is suggested that you find the coordinates of the billboard's 4 corners manually, and then hard-code those coordinates into your solution. Use those coordinates to solve for the appropriate homography and perform the image mapping step.\n","\n","(Credit to the following web sites for billboard and desert images: https://mediavenue.com and https://EgyptTravelBlog.com.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOZjkd_z7zqs"},"outputs":[],"source":["# TO DO:  Write code to display the original billboard image,\n","#  followed by the billboard image after it has been modified\n","#  using the desert image.\n","#\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ic8DE-g5Q5Mv"},"source":["#**Problem 5: Fundamental matrix**\n","\n","##**Getting started**\n","In this problem you will detect SIFT keypoints within two images (a stereo pair), find correspondences, and use those corresponding points to solve for the fundamental matrix *F*  that relates the two images. You must demonstrate a correct result by using *F* to draw epipolar lines for keypoints that you detect.\n","\n","Before we get to the main parts of this problem, run the following code block to display 2 views of Durham Hall."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjJLyVGO2Zpq"},"outputs":[],"source":["# Load and display a stereo image pair\n","#\n","left_img = load_image(\"Durham1.png\")\n","right_img = load_image(\"Durham2.png\")\n","show_image(np.concatenate([left_img, right_img], axis=1))"]},{"cell_type":"markdown","metadata":{"id":"V2XlxO-lLo87"},"source":["Now verify that you can use OpenCV tools to detect SIFT-based keypoints. The following code block should detect keypoints in one of the Durham images, and then display the image using small small circles to indicate keypoint locations.\n","\n","These library functions allow for many options. For example, if you change the `nfeatures` parameter for `SIFT_create`, you'll see different numbers of detected keypoints. You may want to experiment with these parameters later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0lKIlVEIpFC"},"outputs":[],"source":["def testSIFT(img1):\n","  sift = cv2.SIFT_create(nfeatures=500)\n","  kp = sift.detect(img1, None)\n","  img1=cv2.drawKeypoints(img1, kp, None, color=(0, 0, 255))\n","\n","  fig = plt.figure()\n","  fig.set_size_inches(12, 9) # You can adjust the size of the displayed figure\n","  plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n","\n","\n","img = cv2.imread(\"Durham1.png\", cv2.IMREAD_COLOR)\n","testSIFT(img)"]},{"cell_type":"markdown","metadata":{"id":"MpLCobsqG348"},"source":["Next, verify that you can use a matching technique from OpenCV that tries to detect corresponding keypoints between 2 images. This example displays an example with a small number of correspondences.\n","\n","The library function  `cv2.BFmatcher()` is OpenCV's \"brute force\" matcher. More description is given in\n","https://github.com/abidrahmank/OpenCV2-Python-Tutorials/blob/master/source/py_tutorials/py_feature2d/py_matcher/py_matcher.rst"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RWudCkU4oCum"},"outputs":[],"source":["def genSIFTMatchPairs(img1, img2, numberOfMatches):\n","  # Find keypoints and their SIFT descriptors in the two images\n","  sift = cv2.SIFT_create()\n","  kp1, des1 = sift.detectAndCompute(img1, None)\n","  kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","  # Search for corresponding pairs of points\n","  bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","  matches = bf.match(des1, des2)\n","\n","  # Sort them based on distance (dissimilarity) between two descriptors\n","  matches = sorted(matches, key = lambda x:x.distance)\n","\n","  pts1 = np.zeros((numberOfMatches, 2))\n","  pts2 = np.zeros((numberOfMatches, 2))\n","  for i in range(numberOfMatches):\n","    pts1[i,:] = kp1[matches[i].queryIdx].pt\n","    pts2[i,:] = kp2[matches[i].trainIdx].pt\n","  return pts1, pts2, matches[:numberOfMatches], kp1, kp2\n","\n","def testMatchingProcedure():\n","  img1 = cv2.imread('Durham1.png')\n","  img2 = cv2.imread('Durham2.png')\n","\n","  # Perform the matching step (here, only the best 11 correspondences are returned)\n","  pts1, pts2, matches1to2, kp1, kp2 = genSIFTMatchPairs(img1, img2, 11)\n","  # Now pts1 and pts2 should contain lists of corresponding points\n","  #  within img1 and img2, respectively\n","  #  Each point has the format [column row]\n","\n","  # Display the two images to check the results visually\n","  #  (the parameter flags=2 removes unmatched points from the display)\n","  matching_result = cv2.drawMatches(img1, kp1, img2, kp2, matches1to2, None, flags=2,\n","    matchColor = (255, 255, 0), singlePointColor=(0, 0, 255))\n","  fig = plt.figure()\n","  fig.set_size_inches(16, 10) # You can adjust the size of the displayed figure\n","  plt.imshow(cv2.cvtColor(matching_result, cv2.COLOR_BGR2RGB))\n","\n","\n","testMatchingProcedure()"]},{"cell_type":"markdown","metadata":{"id":"Ut59RaQX5gFY"},"source":["The previous steps have shown how you can use OpenCV to find several pairs of corresponding points in two images. For this problem, you need to detect correspondences and use them to solve for the fundamental matrix *F* that relates the two images. You must demonstrate a correct result by using *F* to draw epipolar lines for keypoints that you detect.\n","\n","The main parts of this problem are as follows:\n","\n","*   **Part (a)** Write code that implements the **8-point algorithm to compute *F*.** For a given set of 8 or more correspondences, find a least-squares solution for *F* based on  those image points. An outline of the approach will be given in the lecture slides. You do not need to consider outliers for this problem.  \n","*   **Part (b)** Write a function that uses *F* to **compute the epipoles** for the two images.\n","*   **Part (c)** Write a function to **display two images and highlight keypoints** that have been detected in both images. Also **display epipolar lines** that you obtain using your computed *F* matrix. One or both images should show epipolar lines passing through (or near) those keypoints.\n","*   **Part (d)** Write a function that **combines all of the steps**, including keypoint detection and matching.\n","\n","**Part (a):  8-point algorithm**\n","Implement the following function, as described above.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z4bq1ph2Pu9G"},"outputs":[],"source":["##############################\n","# TO DO: Implement the findFundamentalMatrix function\n","#  (You are allowed to subdivide your code into additional functions that are called by this one)\n","#\n","def findFundamentalMatrix(pts1, pts2, scale):\n","  '''Use the eight-point algorithm to compute the fundamental matrix for the given points.\n","   Input:\n","    pts1: keypoint locations for image 1, shape (N, 2), where N >= 8\n","    pts2: keypoint locations for image 2, with a corresponding point for every one in pts1\n","    scale: use this scale factor to convert all coordinates to the range [0, 1]\n","           (see the additional notes that have been provided for this problem)\n","   Returns:\n","    F: the fundamental matrix, shape (3, 3)\n","  '''\n","  # The following line is just a placeholder. Replace it with your code.\n","  F = np.asarray([[0, 0, 0],[0, 0, -1],[0, 1, 0]])\n","\n","\n","\n","  return F\n"]},{"cell_type":"markdown","metadata":{"id":"KavA_l_gLlkq"},"source":["**Part (b): Epipoles**\n","\n","Write a function that uses *F* to compute the epipoles for the\n","two images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R39KKOyXHO0u"},"outputs":[],"source":["##############################\n","# TO DO: Implement the findEpipoles function\n","#\n","def findEpipoles(F):\n","  '''Compute the two epipoles from a given fundamental matrix\n","   Input:\n","    F: fundamental (or essential) matrix, shape (3, 3)\n","   Returns:\n","    e1, e2: the two epipoles; each is a vector with 3 components\n","  '''\n","  # The following 2 lines are just placeholders. Replace them with your code.\n","  e1 = np.asarray([1, 0, 1])\n","  e2 = np.asarray([0, 1, 1])\n","\n","\n","\n","  return e1, e2\n"]},{"cell_type":"markdown","metadata":{"id":"YaBU7oh0uyYg"},"source":["For grading purposes, run the following code block to print your computed matrix *F*\n","and the two epipoles for the sample points that are given below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GnQqs0i2uN6z"},"outputs":[],"source":["##############################\n","# Do not modify this code block\n","#  (For debugging, you could copy this code to another block and edit it there)\n","\n","# The following are some matching keypoints that were detected in the Durham1 and Durham2 images.\n","pts1_list = [\n","  [224.95256042, 321.64755249],\n","  [280.72879028, 296.15835571],\n","  [302.34194946, 364.82437134],\n","  [434.68283081, 402.86990356],\n","  [244.64321899, 308.50286865],\n","  [488.62979126, 216.26953125],\n","  [214.77470398, 430.75869751],\n","  [299.20846558, 312.07217407],\n","  [266.94125366, 119.36679077],\n","  [384.41549683, 442.05865479],\n","  [475.28448486, 254.28138733]]\n","\n","pts2_list = [\n","  [253.88285828, 335.00772095],\n","  [304.884552,   308.89205933],\n","  [325.33914185, 375.91308594],\n","  [455.15515137, 411.18075562],\n","  [271.48794556, 322.07028198],\n","  [515.11816406, 221.74610901],\n","  [245.31390381, 441.54830933],\n","  [321.74771118, 324.31417847],\n","  [289.86627197, 137.46456909],\n","  [403.3711853,  451.08905029],\n","  [496.16610718, 261.36074829]]\n","\n","pts1 = np.asarray(pts1_list)\n","pts2 = np.asarray(pts2_list)\n","\n","# Compute F and the epipoles;\n","#  scale factor 800 is the largest (row, column) size of the Durham images\n","F = findFundamentalMatrix(pts1, pts2, 800)\n","e1, e2 = findEpipoles(F)\n","\n","# Print F and the epipoles\n","print('F =\\n', F)\n","print('\\n')\n","print('normalized epipole #1:', e1/e1[2])\n","print('normalized epipole #2:', e2/e2[2])\n"]},{"cell_type":"markdown","metadata":{"id":"DIZ56juuWTb4"},"source":["**Part (c): Epipolar lines**\n","\n","Write a function `displayEpipolarLines` that will display two stereo images and highlight keypoints in both images. Also display epipolar lines in at least one of the images. This function should display information for all of the keypoints that are provided to it. For practical reasons, usually it is best to display a small number of keypoints (e.g., 15 or 20, not 200) so that it is relatively easy to see the individual keypoints and lines.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2JT4wLUWhqc8"},"outputs":[],"source":["##############################\n","# TO DO: Implement the displayEpipolarLines function\n","#\n","def displayEpipolarLines(pts1, pts2, F, img1, img2):\n","  '''Display two images with highlighted keypoints and epipolar lines.\n","     Assume that the keypoints have already been detected, and F has already been computed.\n","   Input:\n","    pts1: keypoint locations for image 1, shape (N, 2), where N >= 1\n","    pts2: keypoint locations for image 2, with a corresponding point for every one in pts1\n","    F:  fundamental matrix for the two images\n","    img1: image 1\n","    img2: image 2\n","   Output:\n","    No return value; the output is a visual display\n","  '''\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gT1AbXlXzz5O"},"source":["Run the following code block to test your code. This test uses a precomputed set of 11 correspondences from the Durham images. (Here I'm using 11 correspondences because my least-squared results were much worse with a smaller number. Possible reasons: not well distributed spatially across the images, or lens distortion, etc.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"URtU_0ilzkrR"},"outputs":[],"source":["##############################\n","# Do not modify this code block\n","#  (For debugging, you could copy this code to another block and edit it there)\n","#\n","def testEpipolarLines():\n","  img1 = cv2.imread('Durham1.png')\n","  img2 = cv2.imread('Durham2.png')\n","\n","  # The following are some matching keypoints that were detected in the Durham1 and Durham2 images.\n","  pts1_list = [\n","    [224.95256042, 321.64755249],\n","    [280.72879028, 296.15835571],\n","    [302.34194946, 364.82437134],\n","    [434.68283081, 402.86990356],\n","    [244.64321899, 308.50286865],\n","    [488.62979126, 216.26953125],\n","    [214.77470398, 430.75869751],\n","    [299.20846558, 312.07217407],\n","    [266.94125366, 119.36679077],\n","    [384.41549683, 442.05865479],\n","    [475.28448486, 254.28138733]]\n","\n","  pts2_list = [\n","    [253.88285828, 335.00772095],\n","    [304.884552,   308.89205933],\n","    [325.33914185, 375.91308594],\n","    [455.15515137, 411.18075562],\n","    [271.48794556, 322.07028198],\n","    [515.11816406, 221.74610901],\n","    [245.31390381, 441.54830933],\n","    [321.74771118, 324.31417847],\n","    [289.86627197, 137.46456909],\n","    [403.3711853,  451.08905029],\n","    [496.16610718, 261.36074829]]\n","\n","  pts1 = np.asarray(pts1_list)\n","  pts2 = np.asarray(pts2_list)\n","\n","  # Compute F and the epipoles\n","  #  Scale factor 800 is the largest (row, column) size of the Durham images\n","  Fmat = findFundamentalMatrix(pts1, pts2, 800)\n","  e1tmp, e2tmp = findEpipoles(Fmat)\n","\n","  # Print F and the epipoles\n","  print('Fmat =\\n', Fmat)\n","  print('\\n')\n","  print('normalized epipole #1:', e1tmp/e1tmp[2])\n","  print('normalized epipole #2:', e2tmp/e2tmp[2])\n","\n","  # Display the two images with epipolar lines highlighted\n","  displayEpipolarLines(pts1, pts2, Fmat, img1, img2)\n","\n","\n","testEpipolarLines()\n"]},{"cell_type":"markdown","metadata":{"id":"pgpN-uiRfdLB"},"source":["**Part (d): Full sequence**\n","\n","Write a function that performs the full sequence of operations: load two images, detect SIFT keypoints, perform stereo matching, compute the fundamental matrix, and display the results.\n","\n","Show your results using the files `statue1.png` and `statue2.png`.\n","For all steps up to performing stereo matching, you may borrow liberally from the \"starter code\" in this notebook, although you may need to adjust some of the parameters in order to get good results. To compute the fundamental matrix, you must call your function `findFundamentalMatrix`. To display the results, you must call your function `displayEpipolarLines`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UsfwtfqSfeyf"},"outputs":[],"source":["##############################\n","# TO DO: Implement the following function\n","#\n","def stereoMatchingAndDisplay(img1file, img2file):\n","  '''Extract keypoints from a stereo image pair, find corresponding points,\n","      compute the fundamental matrix (assuming no outliers),\n","      and display the results with sample epipolar lines.\n","   Input:\n","    img1file: name of file containing image 1\n","    img2file: name of file containing image 2\n","   Output:\n","    No return value; the output is a visual display\n","  '''\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5fxTg8X2SbzI"},"source":["Run the following code block to test your  `stereoMatchingAndDisplay` function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKLR5QiuRLOG"},"outputs":[],"source":["##############################\n","# Do not change the first line of code in this block, for the \"statue\" image pair.\n","#  It is okay (but not required) to add more lines that test your stereoMatchingAndDisplay\n","#  function with additional stereo pairs.\n","#\n","stereoMatchingAndDisplay('statue1.png', 'statue2.png')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qxuaGPNKu8nb"},"source":["# **Problem 6: Using RANSAC to deal with outliers**\n","\n","*For ECE 5554 students, this problem is required. For ECE 4554 students, this problem is optional and will count as extra credit.*\n","\n","In the previous problem, undoubtedly you saw that incorrect correspondences can be reported by the OpenCV tools. It is likely that those false matches will act as outliers in your estimation of the fundamental matrix.\n","\n","As discussed during lectures, the RANSAC algorithm is a popular way to deal with outliers during model fitting. Here you must implement the RANSAC approach to compute the fundamental matrix *F*.\n","\n","A suggestion is that you detect *N*>20 correspondences from an image pair, and repeatly call your `findFundamentalMatrix` function with only 8 correspondences that are drawn at random. Based on the computed *F*, determine which correspondences are inliers, and refine your estimate of *F* using all of the inliers.\n","\n","*Note that this problem is more open-ended than previous coding problems.* You need to make choices about what parameters to use, what input images to process, and what results to report. Use comments and print statements (as described below) to tell the grader what you have done. Be sure  to provide clear explanations to the grader.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eTK0nCbXinUT"},"outputs":[],"source":["##############################\n","# TO DO: Implement the following function\n","#  (You are allowed to subdivide your code into additional functions that are called by this one)\n","#\n","def findFundamentalMatrixUsingRansac(pts1, pts2, scale):\n","  '''Use the eight-point algorithm  to compute the fundamental matrix for the given points,\n","     using RANSAC to deal with outliers.\n","   Input:\n","    pts1: keypoint locations for image 1, shape (N, 2), where N >= 8\n","    pts2: keypoint locations for image 2, with a corresponding point for every one in pts1\n","    scale: use this scale factor to convert all coordinates to the range [0, 1]\n","   Returns:\n","    F: the fundamental matrix, shape (3, 3)\n","  '''\n","  # The following line is just a placeholder. Replace it with your code.\n","  F = np.asarray([[0, 0, 0],[0, 0, -1],[0, 1, 0]])\n","\n","\n","\n","\n","  return F\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5lvwzAKes1Kg"},"source":["In the following code block, write code to test the RANSAC method that you have implemented in `findFundamentalMatrixUsingRansac`. Try to select an image pair and algorithm parameters for which RANSAC gives a good improvement over the non-RANSAC 8-point algorithm. Generate and display outputs for both cases, as a  comparison of your results *with* RANSAC and your results *without* RANSAC. Use print statements liberally to explain to the grader the different outputs that you have generated.  As part of your code's comments, describe how you decide which correspondences are outliers. (If convenient, you may also provide additional descriptions in a text block below.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0oLmGJwDsde5"},"outputs":[],"source":["##############################\n","# TO DO: Write code to test your RANSAC implementation (your function findFundamentalMatrixUsingRansac)\n","#\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9oMvIzi4nxPo"},"source":["---\n","# Creating a PDF version of your current notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euPVsDQfn5jq"},"outputs":[],"source":["#The following two installation steps are needed to generate a PDF version of the notebook\n","#(These lines are needed within Google Colab, but are not needed within a local version of Jupyter notebook)\n","!apt-get -qq install texlive texlive-xetex texlive-latex-extra pandoc\n","!pip install --quiet pypandoc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8UGtiNYsoIKJ"},"outputs":[],"source":["# TO DO: Provide the full path to your Jupyter notebook file\n","!jupyter nbconvert --to PDF \"/content/drive/My Drive/Colab Notebooks/HW3/Homework3_USERNAME.ipynb\""]}],"metadata":{"colab":{"collapsed_sections":["Uv_AZs3o90Oo"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}